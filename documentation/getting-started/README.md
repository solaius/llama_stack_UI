# Getting Started with Llama Stack UI

Welcome to the Llama Stack UI getting started guide. This section contains installation instructions for different operating systems and basic setup information.

## Installation Guides

Choose the installation guide that matches your operating system:

- [macOS Installation](./installation_macos.md) - Instructions for installing on macOS
- [Linux Installation](./installation_linux.md) - Instructions for installing on Linux
- [Windows WSL Installation](./installation_windows_wsl.md) - Instructions for installing on Windows with WSL

## Prerequisites

Before installing Llama Stack UI, make sure you have the following prerequisites:

- **Node.js** (v16 or newer)
- **npm** (v7 or newer)
- **Git**
- A running instance of the Llama API server

## Quick Start

After installation, you can start using Llama Stack UI by:

1. Starting the server and client applications
2. Opening your web browser and navigating to the client URL (typically http://localhost:3000)
3. Exploring the available features through the navigation menu

## Next Steps

After installation, you might want to:

- Read the [User Guide](../user/user_guide.md) to learn how to use the application
- Explore the [Agent Management Guide](../guides/agent_management.md) to create your first agent
- Check out the [Chat Interface Guide](../guides/chat_interface.md) to start chatting with agents

## Troubleshooting

If you encounter issues during installation:

- Make sure all prerequisites are installed correctly
- Check that the Llama API server is running and accessible
- Verify that the ports required by the application are not in use by other services
- Check the console output for error messages

For more detailed troubleshooting, refer to the specific installation guide for your operating system.